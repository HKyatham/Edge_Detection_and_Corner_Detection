{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJqSy02hIb4a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_hg_x2hIkLm"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture('proj2_v2.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YlUJzVcoImP_"
      },
      "outputs": [],
      "source": [
        "def convolve(input_image, kernel, padding = 0, stride = 1):\n",
        "    assert (stride > 0), \"stride cannot be less than 1\"\n",
        "\n",
        "    input_image = input_image.reshape(input_image.shape[0], input_image.shape[1], -1) # to handle gray scale images\n",
        "    h, w, c = input_image.shape\n",
        "    kernel_size = kernel.shape[0]\n",
        "    if kernel_size % 2 == 0: #even kernel\n",
        "        print(\"Error! The kernel cannot be even\")\n",
        "        return -1\n",
        "    if kernel.shape[0] is not kernel.shape[1]:\n",
        "        print(\"Error! The kernel is not square\")\n",
        "        return -1\n",
        "\n",
        "    # create padded image\n",
        "    padded_input_image = np.zeros((h + 2*padding,  w + 2*padding, c))\n",
        "    padded_input_image[padding: padding + h, padding: padding + w, :] = input_image\n",
        "    #print(\"Original input image shape : \", input_image.shape)\n",
        "    #print(\"Padded input image shape : \", padded_input_image.shape)\n",
        "\n",
        "    # Perform the gradient\n",
        "    h_out = int((h + padding * 2 - kernel_size) / stride) + 1\n",
        "    w_out = int((w + padding * 2 - kernel_size) / stride) + 1\n",
        "    conv_image = np.zeros((h_out, w_out, c))\n",
        "    for i in range(h_out):\n",
        "        for j in range(w_out):\n",
        "            for k in range(c):\n",
        "                conv_image[i, j, k] = np.sum(padded_input_image[i*stride : (i*stride + kernel_size), \\\n",
        "                                            j*stride : (j*stride + kernel_size), k] * kernel)\n",
        "\n",
        "    #print(\"Convoluted output size : \", conv_image.shape)\n",
        "    return conv_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kjaxmha_Iox3"
      },
      "outputs": [],
      "source": [
        "def process_frame(frame):\n",
        "    # Step 1: Check for blurry frames using Variance of the Laplacian\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # gImg=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
        "    #cv2_imshow(gray)\n",
        "    kernel = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
        "    vImg=convolve(gray, kernel, padding = 0, stride = 1)\n",
        "    #cv2_imshow(vImg)\n",
        "    vMean=np.mean(vImg)\n",
        "    #print(vMean)\n",
        "    vImg-=vMean\n",
        "    #cv2_imshow(vImg)\n",
        "    vImg = vImg.astype(np.uint8)\n",
        "    #print(vImg)\n",
        "    h, w, c = vImg.shape\n",
        "    #print(h,w,c)\n",
        "    varience = sum(sum(vImg))\n",
        "    #print(varience)\n",
        "    if(varience < 150):\n",
        "      print(\"Varience low\", varience)\n",
        "      return None\n",
        "    #   cv2_imshow(frame)\n",
        "    # laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "\n",
        "    # if laplacian_var < 150:\n",
        "    #     return None  # Skip blurry frames\n",
        "\n",
        "    # Step 2: Convert to grayscale and threshold to segment unwanted background\n",
        "    # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    gray = gray[:480,:600]\n",
        "    kernel_size = 3\n",
        "    blur_gray = cv2.medianBlur(gray,kernel_size)\n",
        "    # _, threshHough = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
        "    _, thresh = cv2.threshold(blur_gray, 200, 255, cv2.THRESH_BINARY)\n",
        "    #cv2_imshow(thresh)\n",
        "    # Step 3: Detect edges using Canny edge detector\n",
        "    edges = cv2.Canny(thresh, 150, 250, apertureSize=3)\n",
        "    h, w = edges.shape[:2]\n",
        "    mask = np.zeros((h+2, w+2), np.uint8)\n",
        "    # cv2_imshow(edges)\n",
        "    # cv2_imshow(blur_gray)\n",
        "    cv2.floodFill(edges, mask, (0,0), 123)\n",
        "    floodfill = edges.copy()\n",
        "    # cv2_imshow(floodfill)\n",
        "    bg = np.zeros_like(edges)\n",
        "    # cv2_imshow(bg)\n",
        "    bg[edges == 123] = 255\n",
        "    # cv2_imshow(bg)\n",
        "    #bg = cv2.blur(bg, (3,3))\n",
        "    #cv2_imshow(bg)\n",
        "    edgesMask = cv2.Canny(bg, 100, 250, apertureSize=3)\n",
        "    # cv2_imshow(edgesMask)\n",
        "    # Step 4: Use Hough Transform to extract straight lines\n",
        "    # Step 5: Filter out short lines and keep dominant ones\n",
        "    lines = cv2.HoughLinesP(edgesMask,rho = 1,theta = 1*np.pi/180,threshold = 90,minLineLength = 100,maxLineGap = 50)\n",
        "\n",
        "    # print(lines)\n",
        "    print(lines)\n",
        "    # Step 6: Compute intersections of Hough Lines\n",
        "    valid_corners = []\n",
        "    output_frame = frame.copy()\n",
        "    for line in lines:\n",
        "        x1 = line[0][0]\n",
        "        y1 = line[0][1]\n",
        "        x2 = line[0][2]\n",
        "        y2 = line[0][3]\n",
        "        cv2.line(output_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
        "        valid_corners.append((x1,y1))\n",
        "        valid_corners.append((x2,y2))\n",
        "        valid_corners.append((x1-1,y1-1))\n",
        "        valid_corners.append((x2-1,y2-1))\n",
        "        valid_corners.append((x1+1,y1+1))\n",
        "        valid_corners.append((x2+1,y2+1))\n",
        "        valid_corners.append((x1-1,y1+1))\n",
        "        valid_corners.append((x2-1,y2+1))\n",
        "        valid_corners.append((x1+1,y1-1))\n",
        "        valid_corners.append((x2+1,y2-1))\n",
        "    #cv2_imshow(output_frame)\n",
        "    # Step 7: Filter out extraneous corners\n",
        "    corners = cv2.goodFeaturesToTrack(bg, 100, 0.02, 100)\n",
        "    corners2 = cv2.cornerHarris(bg, 2, 7, 0.01)\n",
        "    cnt = corners2 > 0.01 * corners2.max()\n",
        "    # print(np.where(cnt==True))\n",
        "    # print(corners2)\\\n",
        "    # corners = corners.tolist()\n",
        "    # for i in corners:\n",
        "    #   corners.append([[i[0][0]-1,i[0][1]-1]])\n",
        "    #   corners.append([[i[0][0]+1,i[0][1]+1]])\n",
        "    #   corners.append([[i[0][0]-1,i[0][1]+1]])\n",
        "    #   corners.append([[i[0][0]+1,i[0][1]-1]])\n",
        "    corners = np.intp(corners)\n",
        "    print(corners)\n",
        "\n",
        "    # output_frame[corners2 > 0.01 * corners2.max()] = [0,255,0]\n",
        "\n",
        "    # draw red color circles on all corners\n",
        "    for i in valid_corners:\n",
        "        if i in corners:\n",
        "          cv2.circle(output_frame, i, 3, (0, 0, 225), -1)\n",
        "\n",
        "    # cv2_imshow(output_frame)\n",
        "    return output_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RybyrkSIr3n"
      },
      "outputs": [],
      "source": [
        "cap.set(1, 35)\n",
        "ret, polyFrame = cap.read()\n",
        "cv2.imshow(\"\",polyFrame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRaHKMhDIu-o"
      },
      "outputs": [],
      "source": [
        "# Applying the image processing for specific image.\n",
        "newFrame = process_frame(polyFrame)\n",
        "cv2.imshow(\"\",newFrame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YODBz5sI0Zo"
      },
      "outputs": [],
      "source": [
        "fps = 10\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Create VideoWriter object for output video\n",
        "out = cv2.VideoWriter('hkyatham_project2.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))\n",
        "count = 1\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    print(count)\n",
        "    count+=1\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    processed_frame = process_frame(frame)\n",
        "\n",
        "    if processed_frame is not None:\n",
        "        out.write(processed_frame)\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
